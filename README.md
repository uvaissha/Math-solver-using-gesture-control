# ✋🧮 Gesture-Controlled Math Solver

An AI-powered web application that lets users **write and solve mathematical equations using hand gestures**. Built with Python, OpenCV, Mediapipe, Streamlit, and Google’s Gemini AI, this project offers an innovative way to interact with math—without a keyboard or touchscreen.

---

## 📌 Project Overview

Traditional input methods like keyboards and touchscreens can limit speed and accessibility, especially in learning environments. This project introduces a real-time, gesture-controlled interface for writing and solving mathematical equations—perfect for education, AR/VR interfaces, and assistive technologies.

---

## 🚀 Features

- ✍️ Real-time hand gesture tracking for drawing math expressions  
- 🔍 Gesture-to-text conversion using AI-powered recognition  
- 💡 Equation solving using **Gemini AI API**  
- 🌐 Interactive **Streamlit** web interface for smooth user experience  
- 📊 No need for keyboards or styluses—just your hand!

---

## 🛠️ Tech Stack

| Category       | Tools Used                           |
|----------------|--------------------------------------|
| Programming    | Python                               |
| Libraries      | OpenCV, Mediapipe, CVZone, NumPy     |
| AI Integration | Gemini AI (Google)                   |
| UI Framework   | Streamlit                            |
| ML Framework   | TensorFlow / Keras (optional future use) |

---

## 🧩 Modules

1. **Hand Detection Module** – Tracks hand movements using Mediapipe.  
2. **Drawing Module** – Captures strokes to mimic handwriting.  
3. **AI Processing Module** – Converts strokes into mathematical equations and solves them.  
4. **User Interface Module** – Displays input/output via an interactive Streamlit app.

---

## 🧪 How It Works

1. **Hand Tracking**: Detects finger movement and records strokes.  
2. **Drawing Canvas**: Mimics writing on a virtual board.  
3. **AI Integration**: Sends strokes to Gemini AI for equation recognition and solution.  
4. **Output Display**: Shows the solution in real-time on the UI.

---

## 📅 Development Timeline

| Phase | Description |
|-------|-------------|
| Week 1–2 | Research & Requirements |
| Week 3–4 | Gesture Detection Development |
| Week 5–6 | AI Integration |
| Week 7–8 | Streamlit UI |
| Week 9–10 | Testing & Optimization |
| Week 11–12 | Deployment & Documentation |

---

## 🎯 Expected Outcome

- Real-time math-solving using gestures  
- AI-generated solutions for handwritten expressions  
- Enhanced educational experience through intuitive design  

---

## 🔮 Future Enhancements

- 🎙️ Voice input support  
- 🧠 Improved OCR using LLMs for complex expressions  
- 🕶️ AR/VR integration for immersive learning  
- 👨‍👩‍👧‍👦 Multi-user collaboration features  
- 🕹️ Gamification for student engagement  

---

## 👨‍💻 Authors

- Abhinav N (KSD21IT001)  
- Mahin Shabaz T A (KSD21IT014)  
- Mahroofa Nasreen V T (KSD21IT015)  
- Muhammed Uvais K (KSD21IT016)  
**Guide:** Prof. V Nayana Murali, Dept. of CSE

---

## 📚 References

1. Garcia, F. & Silva, M. (2019). *OpenCV-based Hand Tracking*.  
2. Chen, Y. & Li, D. (2021). *Gesture-Based Input Systems*.  
3. Miller, H. & Evans, J. (2020). *AI in STEM Education*.  
4. Singh, R. & Gupta, P. (2020). *Generative AI in Interactive Systems*.  
5. Zhang, L. & Lee, K. (2021). *Gesture Recognition in Education*.

---

## 📷 Screenshots

_(Add screenshots of the gesture canvas, equation input, and solution UI here)_

---

## 🧠 License

This project is licensed under the MIT License – feel free to use, modify, and share with credit.

